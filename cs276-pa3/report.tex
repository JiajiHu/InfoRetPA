\documentclass[10pt,twocolumn]{article}
\usepackage{fullpage,enumerate,amsmath,amssymb,graphicx,setspace,epstopdf,float,multirow}

\begin{document}
\title{CS 276 Programming Assignment 3 Project Report}
\author{Jiaji Hu, Xuening Liu}
\date{}
\maketitle

\section{Task 1: Cosine Similarity}

Our weights for task 1:
\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
Parameter & value \\\hline
task1\_W\_url & 2.9\\\hline
task1\_W\_title & 3.5\\\hline
task1\_W\_body & 0.8\\\hline
task1\_W\_header & 1.6\\\hline
task1\_W\_anchor & 0.5\\\hline
body\_len\_normalization & 500\\\hline
tf\_scaling & linear\\\hline
\end{tabular}
\end{table}
NOTE: discuss ``linear vs sublinear" for term frequency -- document and query.

NOTE: give values for weights and discuss intuition. Format: ``task1\_W\_url", etc.

What was the reasoning behind giving the weights to the url, title,
body, header and anchor fields for the three tasks? Were there any
particular properties about the documents that allowed a higher weight
to be given to one field as opposed to another?



\section{Task 2: BM25F}
Our parameters for task 2:
\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
Parameter & value \\\hline
task2\_W\_url & 3.3\\\hline
task2\_W\_title & 5.2\\\hline
task2\_W\_body & 0.9\\\hline
task2\_W\_header & 2.85\\\hline
task2\_W\_anchor & 3.45\\\hline
task2\_B\_url & 0.0\\\hline
task2\_B\_title & 0.2\\\hline
task2\_B\_body & 0.8\\\hline
task2\_B\_header & 0.5\\\hline
task2\_B\_anchor & 0.0\\\hline
tf\_scaling & sublinear\\\hline
K1 & 4.9\\\hline
$\lambda$ & 3.25\\\hline
$\lambda'$ & 0.05\\\hline
$\lambda''$ & 0.1\\\hline
\end{tabular}
\end{table}
Where the function $V_j$ is as follows:
\begin{equation*}
V_j = \frac{1}{\lambda'+\exp({-f_j\lambda''})}
\end{equation*}

NOTE: give values for weights and discuss intuition.

What was the reasoning behind giving the weights to the url, title,
body, header and anchor fields for the three tasks? Were there any
particular properties about the documents that allowed a higher weight
to be given to one field as opposed to another?

In BM25F, in addition to the weights given to the fields, there are
8 other parameters, Burl;Btitle;Bheader;Bbody;Banchor, lambda; lambda\_prime and K1.
How do these parameters affect the ranking function?

In BM25F, why did you select a particular Vj function?

\section{Task 3: Smallest Window}
Our parameters for task 2:
\begin{table}[H]
\centering
\begin{tabular}{|c|c|}
\hline
Parameter & value \\\hline
task2\_W\_url & 3.3\\\hline
task2\_W\_title & 5.2\\\hline
task2\_W\_body & 0.9\\\hline
task2\_W\_header & 2.85\\\hline
task2\_W\_anchor & 3.45\\\hline
task2\_B\_url & 0.0\\\hline
task2\_B\_title & 0.2\\\hline
task2\_B\_body & 0.8\\\hline
task2\_B\_header & 0.5\\\hline
task2\_B\_anchor & 0.0\\\hline
tf\_scaling & sublinear\\\hline
K1 & 4.9\\\hline
$\lambda$ & 3.25\\\hline
$\lambda'$ & 0.05\\\hline
$\lambda''$ & 0.1\\\hline
B & \\\hline

\end{tabular}
\end{table}
Where the page rank function $V_j$ is as follows:
\begin{equation*}
V_j = \frac{1}{\lambda'+\exp({-f_j\lambda''})}
\end{equation*}
And smallest window boosting function is as follows:
\begin{equation*}
score = score \times [1+(B-1)\exp(query\_len-win\_size)]
\end{equation*}

NOTE: give values for weights and discuss intuition.
What was the reasoning behind giving the weights to the url, title,
body, header and anchor fields for the three tasks? Were there any
particular properties about the documents that allowed a higher weight
to be given to one field as opposed to another?

For a function that includes the smallest window as one component,
how does varying B and the boost function change the performance
of the ranking algorithm?

\section{Task 4: Extra Credit}

\section{Analysis}
NOTE: compare ranking functions

What was the reasoning behind giving the weights to the url, title,
body, header and anchor fields for the three tasks? Were there any
particular properties about the documents that allowed a higher weight
to be given to one eld as opposed to another?

What other metrics, not used in this assignment, could be used to
get a better scoring function from the document? The metrics could
either be static (query-independent, e.g. document length) or dynamic
(query-dependent, e.g. smallest window).

\section{ideas}
\begin{enumerate}
\item 
Tuning weights of fields: Increase one weight at a time, monitor change in performance.
\item
NOTE: report stats on both training and dev data!
\item 
experiment with stemming? experiment with other smoothing strategies?(cosine body length).
\end{enumerate}

\end{document}